{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Distributions, error, correlation, and p-values\n",
    "### Spring 2023, Week 2\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "- Become acquainted with Jupyter notebooks\n",
    "- Learn about association, correlation, and causation\n",
    "- Gain intuition about statistical tests and sample sizes\n",
    "- Read basic python syntax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of bash commands to make google colab work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr23/week2_distributions\n",
    "!mkdir ./data\n",
    "!cp week2_distributions/data/* ./data\n",
    "!cp week2_distributions/clean_data.py ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "\n",
    "Import statements are used to integrate *external code or packages* into our analysis. \n",
    "\n",
    "- `pandas`: Represents data as tables\n",
    "- `seaborn`: Data exploration visualization tool\n",
    "- `ipywidgets`: Notebook widgets that add user interfaces to notebooks\n",
    "- `random`: Generate random numbers\n",
    "- `numpy`: General math/matrices package\n",
    "- `matplotlib`: Data visualization software\n",
    "- `Scipy`: General scientific computing\n",
    "\n",
    "Using `as` will alias (rename) the package in the code.\n",
    "`matplotlib.pyplot` is importing the submodule `pyplot` from `matplotlib`. \n",
    "`from scipy.stats` is telling python where to find `ttest_ind`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (12,12)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1) #Change from 1 to 1.5 or 2 if you have a hard time reading text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor: Common data visualizations\n",
    "\n",
    "This first section is just to familiarize you with common data visualizations for distributions and continuous variables. \n",
    "It will also introduce you to many of the interactive buttons that you'll see throughout the notebook.\n",
    "First we are going to create a toy dataset using a random number generator. \n",
    "Here we use the Normal distribution function (pdf):\n",
    "\n",
    "\n",
    "$$\n",
    "  f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \n",
    "  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\n",
    "$$\n",
    "\n",
    "Another way that this statement is equivalently written is: \n",
    "\n",
    "$$ X \\sim \\mathcal{N}(\\mu, \\sigma^2) $$\n",
    "\n",
    "Or that X comes from a normal distribution with a mean (expected value) of $\\mu$ and a variance of $\\sigma^2$. We use this shorthand as those are the only unknown constants in the equation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_distribution(n = 100, mu = 6, sigma = 2):\n",
    "    return [random.gauss(mu, sigma) for _ in range(0,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a_histogram(x, n, mu, sigma):\n",
    "    \"\"\"Generate annotated histogram based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    plt.figure(figsize=FIG_SIZE)\n",
    "    sns.histplot(x, color=data_color, kde=True, stat=\"probability\")\n",
    "    _, xmax, _, ymax = plt.axis()\n",
    "    plt.title(\"Histogram of random values generated from a normal distribution\", fontsize=TITLE_FONT)\n",
    "    \n",
    "    plt.axvline(mu, linestyle='--', color=annotation_color, lw=3)\n",
    "    plt.text(mu, .97*ymax, r' $\\mu$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "    \n",
    "    plt.axvline(mu+sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu+sigma, .97*ymax, r' $\\mu+\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "\n",
    "    plt.axvline(mu-sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu-sigma, .97*ymax, r' $\\mu-\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"right\")\n",
    "    \n",
    "    plt.text(.8*xmax, .9*ymax, 'Data', color=data_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    plt.text(.8*xmax, .93*ymax, 'Underlying distribution', color=annotation_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    \n",
    "    sns.despine()\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "@widgets.interact_manual(n=(3,1000), mu=(-10, 10), sigma=(0,10))\n",
    "def create_histplot(n=100, mu=6, sigma=2): \n",
    "    \"\"\"Wrapper function for widgets decorator and plot_a_histogram()\"\"\"\n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu, sigma=sigma)\n",
    "    plot_a_histogram(toy_dataset_x, n, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Histograms__ use discrete bins (range of values) to categorize data, and are used primarily to visualize probability or proportions. Most visualizations of probability are based on histogram-like structures, and the kernel density estimate (KDE) line is the best guess at an underlying distribution. The higher the bar in a bin, the more times a value occurs in that bin within a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a_boxplot(x, n, mu, sigma, swarm):\n",
    "    \"\"\"Generate annotated boxplot based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(data=x, color=data_color,orient='h', boxprops=dict(alpha=.5), showmeans=True,\n",
    "                meanprops={\"marker\":\"o\",\n",
    "                           \"markerfacecolor\":\"white\", \n",
    "                           \"markeredgecolor\":\"black\",\n",
    "                           \"markersize\":\"6\"})\n",
    "    if swarm: sns.stripplot(data=x, orient='h',size=5, color=\".3\", linewidth=0)\n",
    "    \n",
    "    _, xmax, _, ymax = plt.axis()\n",
    "    plt.title(\"Boxplot of random values generated from a normal distribution\", fontsize=TITLE_FONT)\n",
    "    \n",
    "    plt.axvline(mu, linestyle='--', color=annotation_color, lw=3)\n",
    "    plt.text(mu, -0.9*ymax, r' $\\mu$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "    \n",
    "    plt.axvline(mu+sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu+sigma, -0.9*ymax, r' $\\mu+\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "\n",
    "    plt.axvline(mu-sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu-sigma, -0.9*ymax, r' $\\mu-\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"right\")\n",
    "    \n",
    "    plt.text(0.75*xmax, 0.6*ymax, 'Data', color=data_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    plt.text(0.75*xmax, 0.8*ymax, 'Underlying distribution', color=annotation_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    sns.despine()\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "@widgets.interact_manual(n=(3,1000), mu=(-10, 10), sigma=(0,10))\n",
    "def create_boxplot(n=100, mu=6, sigma=2, show_individual_points=False): \n",
    "    \"\"\"Wrapper function for widgets decorator and plot_a_boxplot()\"\"\"\n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu, sigma=sigma)\n",
    "    plot_a_boxplot(toy_dataset_x, n, mu, sigma, swarm=show_individual_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Box plots__ are common for comparing data, which we will be using later. The _box_ represents the interquartile range, or the data that contains the middle 50 percent of the data. The _whiskers_ represent the range of the distribution, adjusted for outliers, represented by _diamonds_. The _circle_ represents the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a_scatterplot(x, y, n, mu_x, sigma_x, mu_y, sigma_y):\n",
    "    \"\"\"Generate annotated boxplot based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    sns.jointplot(x=x, \n",
    "                  y=y,\n",
    "                  kind=\"reg\",color=data_color,\n",
    "                  marginal_kws=dict(bins=10,color=annotation_color));\n",
    "    plt.xlabel(r\"X data $\\mu={0}$,$\\sigma={1}$\".format(mu_x,sigma_x))\n",
    "    plt.ylabel(r\"Y data $\\mu={0}$,$\\sigma={1}$\".format(mu_y,sigma_y))\n",
    "\n",
    "    sns.despine()\n",
    "    plt.show()  \n",
    "    \n",
    "@widgets.interact_manual(n=(3,1000), mu_x=(-10, 10), sigma_x=(0,10), mu_y=(-10, 10), sigma_y=(0,10))\n",
    "def create_scatterplot(n=100, mu_x=6, sigma_x=2, mu_y=6, sigma_y=2): \n",
    "    \"\"\"Wrapper function for widgets decorator and plot_a_scatterplot()\"\"\"\n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu_x, sigma=sigma_x)\n",
    "    toy_dataset_y = generate_normal_distribution(n=n, mu=mu_y, sigma=sigma_y)\n",
    "    plot_a_scatterplot(toy_dataset_x, toy_dataset_y, n, mu_x, sigma_x, mu_y, sigma_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatter plots__ are designed to show *pairs* of data points. Each X-axis data point is associated with a Y-axis data point. These plots will be common when we're talking about associations between continuous variables, specifically for discussions of correlation (and regression - you can ignore the line through the points for now). The histograms have been included to help associate the data sets to the scatter points. Remember, these data were randomly generated and paired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classwork starts here:\n",
    "\n",
    "# Question 1: Introduce yourself to your group!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can ignore the code below! It is setting up an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_datasets(n, rng, repetitions=200):\n",
    "    \"\"\"Generate (repititions) of sample averages, based on (n) samples per average\"\"\"\n",
    "    averages = []\n",
    "    all_nums = []\n",
    "    for i in range(0, repetitions):\n",
    "        nums = [generate_random_numbers(rng) for _ in range(0,n)]\n",
    "        all_nums += nums\n",
    "        averages.append(np.mean(nums))\n",
    "    return all_nums, averages\n",
    "    \n",
    "def generate_histograms_clt(axs, n=10, rng=\"uniform\"):\n",
    "    \"\"\"build 2x2 matrix of histograms\"\"\"\n",
    "\n",
    "    all_nums_fixed, averages_fixed = get_random_datasets(10, rng)\n",
    "    build_paired_histograms(averages_fixed, all_nums_fixed, 10, rng, axs, column=0)\n",
    "    \n",
    "    all_nums, averages = get_random_datasets(n, rng)\n",
    "    build_paired_histograms(averages, all_nums, n, rng, axs, column=1)\n",
    "    \n",
    "def build_paired_histograms(averages, all_nums, n, rng, axs, column):\n",
    "    \"\"\"histogram plotting specific to this lecture\"\"\"\n",
    "    colors=[\"#1e81b0\", \"#e28743\"]\n",
    "    color = colors[column]\n",
    "    axs[0,column].set_title(f\"random samples\")\n",
    "    axs[1,column].set_title(f\"sample averages\")\n",
    "    axs[0,column].text(0.9, 0.9, f\"n:{n}\"+r\" $\\mu$: {0:.2f}, $\\sigma$:{1:.2f}\".format(np.mean(all_nums), np.std(all_nums)) ,\n",
    "                       verticalalignment='bottom', horizontalalignment='right',\n",
    "                       transform=axs[0,column].transAxes,\n",
    "                       color=color, fontsize=LABEL_FONT)\n",
    "    axs[1,column].text(0.9, 0.9, f\"n:{n}\"+r\" $\\hat{{\\mu}}_\\bar{{X}}$: {0:.2f}, $\\hat{{\\sigma}}_\\bar{{X}}$:{1:.2f}\".format(np.mean(averages), np.std(averages)),\n",
    "                       verticalalignment='bottom', horizontalalignment='right',\n",
    "                       transform=axs[1,column].transAxes,\n",
    "                       color=color, fontsize=LABEL_FONT)\n",
    "    sns.histplot(all_nums, ax=axs[0, column], color = color, stat=\"probability\", kde=True)\n",
    "    sns.histplot(averages, bins=10, ax=axs[1, column], color = color, stat=\"probability\", kde=True)\n",
    "    axs[1, column].set_xlim(0,10)\n",
    "    \n",
    "    \n",
    "def generate_random_numbers(generator = \"uniform\"):\n",
    "    \"\"\"generate random numbers with a mean of 5\"\"\"\n",
    "    if generator == \"uniform\": return random.uniform(0,10)\n",
    "    elif generator == \"exponential\": return random.expovariate(1/5)\n",
    "    elif generator == \"normal\": return random.gauss(5,2)\n",
    "    \n",
    "def format_plots(axs):\n",
    "    \"\"\"some extra formatting for subplots\"\"\"\n",
    "    for ax in axs.flat:\n",
    "        title = ax.get_title()\n",
    "        ax.set_title(title, fontweight=\"bold\", size=LABEL_FONT)\n",
    "        ax.set_ylabel('Proportion (Probability)', fontsize = LABEL_FONT)\n",
    "        ax.set_xlabel('Number', fontsize = LABEL_FONT)\n",
    "        ax.tick_params(labelsize=TICK_FONT)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: The central limit theorem \n",
    "\n",
    "\n",
    "There are a number of different ways that the CLT can be proven, but the CLT states the following:\n",
    "\n",
    "$$\\bar{X} \\xrightarrow[]{d} \\mathcal{N}\\Big(\\mu, \\frac{\\sigma^2}{n}\\Big)$$\n",
    "\n",
    "This means that with repeated sampling, $\\bar{X}$ will converge to a normal distribution, centered at $\\mu$ or the mean of the original distribution, with a standard deviation of $\\sigma/\\sqrt{n}$ (variance of $\\sigma^2/n$) or the standard deviation of our original distribution divided by the number of samples included in the average. We will show by using the following procedure:\n",
    "\n",
    "Here we a couple of plots for you to interact with. The left-side plots are fixed to collecting 10 samples from the distribution. The top row of plots shows the histograms of the underlying data points (here n samples x 200 repititions) and the bottom row shows the distribution of averages (200 repititions). Things to think about: Are the results what you would expect from the central limit theorem (CLT)? Does it hold true for other distributions? Is there a distribution shown here that the CLT does not hold true for? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact_manual(n=(3,100),  generator=[\"uniform\",\"exponential\",\"normal\"])\n",
    "def demonstrate_clt(n=10, generator=\"exponential\"):\n",
    "    \"\"\"wrapper function for CLT and widgets decorator\"\"\"\n",
    "    random.seed(10)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=FIG_SIZE, constrained_layout=True)\n",
    "    fig.suptitle(f\"Random number generator (distribution): {generator}\",fontweight=\"bold\", size=TITLE_FONT)\n",
    "    generate_histograms_clt(axs, n, generator)\n",
    "    format_plots(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context: Understanding our data\n",
    "\n",
    "We are going to import a dataset using another python script. The python script is loading the file and doing some basic cleaning of parts of the dataset we aren't using. It can be found in `clean_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clean_data #helper function with \n",
    "\n",
    "cancer_dataset = clean_data.generate_clean_dataframe()\n",
    "cancer_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a basic understanding of the structure of the data now. \n",
    "\n",
    "From the data source: Wisconsin Diagnostic Breast Cancer (WDBC)\n",
    "\n",
    "```\n",
    "\tFeatures are computed from a digitized image of a fine needle\n",
    "\taspirate (FNA) of a breast mass.  They describe\n",
    "\tcharacteristics of the cell nuclei present in the image.\n",
    "\tA few of the images can be found at\n",
    "\thttp://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "\tSeparating plane described above was obtained using\n",
    "\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "\tConstruction Via Linear Programming.\" Proceedings of the 4th\n",
    "\tMidwest Artificial Intelligence and Cognitive Science Society,\n",
    "\tpp. 97-101, 1992], a classification method which uses linear\n",
    "\tprogramming to construct a decision tree.  Relevant features\n",
    "\twere selected using an exhaustive search in the space of 1-4\n",
    "\tfeatures and 1-3 separating planes.\n",
    "\n",
    "\tThe actual linear program used to obtain the separating plane\n",
    "\tin the 3-dimensional space is that described in:\n",
    "\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "\tProgramming Discrimination of Two Linearly Inseparable Sets\",\n",
    "\tOptimization Methods and Software 1, 1992, 23-34].\n",
    "    \n",
    "    Source:\n",
    "    W.N. Street, W.H. Wolberg and O.L. Mangasarian \n",
    "\tNuclear feature extraction for breast tumor diagnosis.\n",
    "\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\n",
    "\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "```\n",
    "\n",
    "What do all the column names mean?\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry \n",
    "- fractal dimension (\"coastline approximation\" - 1) - a measure of \"complexity\" of a 2D image.\n",
    "\n",
    "\n",
    "Cateogory Distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to show the first five values in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset[\"mean_area\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to show the first five values from the groups in the diagnosis column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset[\"mean_area\"].groupby(\"diagnosis\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to calculate basic descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_count(x):\n",
    "    \"\"\"calculate how many values are in a dataset\"\"\"\n",
    "    return len(x)\n",
    "\n",
    "def calculate_mean(x):\n",
    "    \"\"\"get the sample mean\"\"\"\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "def calculate_variance(x):\n",
    "    \"\"\"calculate variance of the dataset\"\"\"\n",
    "    return calculate_mean((x - calculate_mean(x))**2)\n",
    "\n",
    "def calculate_std(x):\n",
    "    \"\"\"calculate standard deviation from the square of the variance\"\"\"\n",
    "    return np.sqrt(np.sum((x - calculate_mean(x))**2)/(len(x)-1))\n",
    "\n",
    "area = cancer_dataset[\"mean_area\"]\n",
    "\n",
    "print(f\"count =  {calculate_count(area):.0f}\")\n",
    "print(f\"mean =  {calculate_mean(area):.2f}\")\n",
    "print(f\"var =  {calculate_variance(area):.2f}\")\n",
    "print(f\"std =  {calculate_std(area):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has us covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dataset[\"mean_area\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Comparing variables\n",
    "\n",
    "What if we're interested in the relationship between variables? Here we calculate the Pearson correlation coefficient $\\rho$. Which variables appear correlated? Which don't appear correlated? Is there a variable that appears correlated but likely not informative? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plots of the various features\n",
    "def calculate_correlation(x,y):\n",
    "    \"\"\"calculate pearson correlation\"\"\"\n",
    "    return calculate_mean((x - calculate_mean(x)).transpose() * (y - calculate_mean(y))) / np.sqrt(calculate_variance(x) * calculate_variance(y))\n",
    "    \n",
    "@widgets.interact(x=list(cancer_dataset), y=list(cancer_dataset))    \n",
    "def make_scatterplot(x=\"mean_radius\",y=\"mean_area\"):\n",
    "    \"\"\"make scatterplot with correlation value and regplot\"\"\"\n",
    "    colors=[\"#e28743\", \"#1e81b0\"]\n",
    "\n",
    "    corr = calculate_correlation(cancer_dataset[x], cancer_dataset[y])\n",
    "    index = int(corr > 0.5)\n",
    "    color = colors[index]\n",
    "    plt.title(r\"correlation: $\\rho = ${:.3f}\".format(corr), color= color, size=TITLE_FONT)\n",
    "    sns.scatterplot(data=cancer_dataset, x=x, y=y, alpha=0.5, color=color);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Robustness of the _t_-test\n",
    "\n",
    "### Comparing the pdf of the _t_ distribution and the normal distribution\n",
    "\n",
    "The t-test is a largely robust method of comparing the mean to a value or the mean of another group. The method is generally robust for skewed distributions. Here we are going to compare the t-distribution to the normal distribution. Keeping in mind the CLT, what can we say about the point of diminishing returns with the $t$-distribution? Is there a cutoff point for degrees of freedom? (There is no simple answer here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t, norm\n",
    "\n",
    "@widgets.interact_manual(df=(3,100))\n",
    "def t_vs_norm(df=3):\n",
    "    \"\"\"plot the t-distribution vs the normal distribution pdfs\"\"\"\n",
    "    x = np.linspace(t.ppf(0.01, df), t.ppf(0.99, df), 100)\n",
    "    x = np.linspace(norm.ppf(0.01), norm.ppf(0.99), 100)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "    ax.plot(x, t.pdf(x,df),'-', lw=5, alpha=0.6, label='t-distribution pdf')\n",
    "    ax.plot(x, norm.pdf(x),'k:', lw=5, alpha=0.6, label='normal distribution pdf')\n",
    "    plt.ylabel(\"Probability\", fontsize=LABEL_FONT)\n",
    "    plt.legend(loc=\"best\",fontsize=LABEL_FONT)\n",
    "    plt.xlabel(\"X\", fontsize=LABEL_FONT)\n",
    "    plt.title(r\"Student's $t$-Distribution vs. Normal Distribution\", fontsize=TITLE_FONT)\n",
    "    plt.ylim(0,.5)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
